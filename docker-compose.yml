version: '3.3'

services:
  #  Zookeepers
  zookeeper:
    image: zookeeper:3.7.0
    networks:
      - broker-kafka
    restart: always
    hostname: zookeeper
    ports:
      - 2181:2181
    environment:
      JVMFLAGS: -Xmx256m
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181
      ZOO_4LW_COMMANDS_WHITELIST: "*"
    healthcheck:
      test: [ "CMD-SHELL", "echo ruok | nc -w 2 zookeeper 2181" ]
      interval: 5s
      timeout: 3s
      retries: 2
    logging:
      options:
        max-size: "512k"
        max-file: "10"
  zoonavigator:
    image: elkozmon/zoonavigator:latest
    restart: always
    ports:
      - 9000:9000
  #schema-registry
  schemaregistry:
    image: confluentinc/cp-schema-registry:6.2.0
    restart: always
    depends_on:
      - zookeeper
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: "zookeeper:2181"
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8085"
    ports:
      - 8085:8085
    logging:
      options:
        max-size: "512k"
        max-file: "10"

  #kafka broker
  kafka1:
    image: confluentinc/cp-kafka:6.2.0
    networks:
      - broker-kafka
    depends_on:
      - zookeeper
      - schemaregistry
    ports:
      - "19092:19092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:19092
      KAFKA_BROKER_ID: 1
      KAFKA_BROKER_RACK: "r1"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SCHEMA_REGISTRY_URL: "schemaregistry:8085"
      #      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      #   KAFKA_LOG_DIRS: "/var/lib/kafka/data1_0"
      KAFKA_JMX_PORT: 9991
      KAFKA_HEAP_OPTS: -Xmx512M -Xms512M

    logging:
      options:
        max-size: "512k"
        max-file: "10"

  kafka2:
    image: confluentinc/cp-kafka:6.2.0
    networks:
      - broker-kafka
    depends_on:
      - zookeeper
      - schemaregistry
    ports:
      - "29092:29092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_BROKER_ID: 2
      KAFKA_BROKER_RACK: "r2"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SCHEMA_REGISTRY_URL: "schemaregistry:8085"
      #KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      #  KAFKA_LOG_DIRS: "/var/lib/kafka/data2_0"
      KAFKA_JMX_PORT: 9991
      KAFKA_HEAP_OPTS: -Xmx512M -Xms512M

    logging:
      options:
        max-size: "512k"
        max-file: "10"
  kafka3:
    image: confluentinc/cp-kafka:6.2.0
    networks:
      - broker-kafka
    depends_on:
      - zookeeper
      - schemaregistry
    ports:
      - "39092:39092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092,PLAINTEXT_HOST://localhost:39092
      KAFKA_BROKER_ID: 3
      KAFKA_BROKER_RACK: "r3"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SCHEMA_REGISTRY_URL: "schemaregistry:8085"
      #KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      #  KAFKA_LOG_DIRS: "/var/lib/kafka/data3_0"
      KAFKA_JMX_PORT: 9991
      KAFKA_HEAP_OPTS: -Xmx512M -Xms512M

    logging:
      options:
        max-size: "512k"
        max-file: "10"

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    networks:
      - broker-kafka
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    ports:
      - 19000:9000
    environment:
      KAFKA_BROKERCONNECT: kafka:9092

  connect:
    image: confluentinc/cp-kafka-connect:latest
    depends_on:
      - zookeeper
      - kafka1
      - kafka2
      - kafka3
      - schemaregistry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka1:9092,kafka2:9092,kafka3:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group-4
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schemaregistry:8085'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.protobuf.ProtobufConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schemaregistry:8085'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "ERROR"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "2"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "2"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "2"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: 'All'
      mem_limit: '2gb'
    command:
      - bash
      - -c
      - |
        echo "Installing Connector"
        confluent-hub install  --no-prompt confluentinc/kafka-connect-jdbc:10.2.0
        confluent-hub install --no-prompt confluentinc/connect-transforms:latest
        confluent-hub install confluentinc/kafka-connect-protobuf-converter:7.0.1
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &
        #
        sleep infinity
    logging:
      options:
        max-size: "512k"
        max-file: "10"
    healthcheck:
      test: [ "CMD-SHELL", "curl localhost:8083/connectors" ]
      interval: 5s
      timeout: 3s
      retries: 2

  db:
    image: postgis/postgis:14-master
    networks:
      - broker-kafka
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
     - '5432:5432'

  #  primary-ksqldb-server:
  #    image: confluentinc/ksqldb-server:latest
  #    hostname: primary-ksqldb-server
  #    container_name: primary-ksqldb-server
  #    depends_on:
  #      - kafka1
  #      - schemaregistry
  #    ports:
  #      - "8088:8088"
  #    environment:
  #      KSQL_LISTENERS: http://0.0.0.0:8088
  #      KSQL_BOOTSTRAP_SERVERS: kafka1:9092,kafka2:9092,kafka3:9092
  #      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schemaregistry:8085
  #      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
  #      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
  #
  #  additional-ksqldb-server:
  #    image: confluentinc/ksqldb-server:latest
  #    hostname: additional-ksqldb-server
  #    depends_on:
  #      - primary-ksqldb-server
  #    ports:
  #      - "8090"
  #    environment:
  #      KSQL_LISTENERS: http://0.0.0.0:8090
  #      KSQL_BOOTSTRAP_SERVERS: kafka1:9092,kafka2:9092,kafka3:9092
  #      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schemaregistry:8085
  #
  #  # Access the cli by running:
  #  # > docker-compose exec ksqldb-cli  ksql http://primary-ksqldb-server:8088
  #  ksqldb-cli:
  #    image: confluentinc/ksqldb-cli:latest
  #    container_name: ksqldb-cli
  #    depends_on:
  #      - primary-ksqldb-server
  #    entrypoint: /bin/sh
  #    tty: true

  akhq:
    # build:
    #   context: .
    image: tchiotludo/akhq
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka1:9092,kafka2:9092,kafka3:9092"
              schema-registry:
                url: "http://schemaregistry:8085"
              connect:
                - name: "connect"
                  url: "http://connect:8083"
    ports:
      - 8090:8080
    links:
      - kafka1
      - schemaregistry

networks:
  broker-kafka:
    driver: bridge